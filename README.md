# UIRE-Net

# Requirements
Python > 3.6

opencv

torchvision 0.2.1

# Test:

python test.py 

The script will process the images in the folders of "test" folder and the result will be in the "result" folder. 

(The training code will be given after the acceptance of the article)


Result:

![1691492825931](https://github.com/Chenxy875/UIRE-Net/assets/121841006/f8a2fdbe-3239-4e81-a5dc-4c777290647a)




You  can find the low-light construction dataset in google driven (It's coming!). 
Datasets:
![1691492902785](https://github.com/Chenxy875/UIRE-Net/assets/121841006/814bca86-2a37-4d35-8037-b50c47d0d545)

Backbone network:
![FIGPIP](https://github.com/Chenxy875/UIRE-Net/assets/121841006/fa292b28-8724-44fd-8afe-c328a3093520)

Feature extraction:
![VGG16](https://github.com/Chenxy875/UIRE-Net/assets/121841006/b0dd90e4-0b2f-4449-b79b-ecb747c053ed)

Ablation results:
![ablation](https://github.com/Chenxy875/UIRE-Net/assets/121841006/e6d2fd5f-fce7-409c-bdcf-0a94e9f3e050)


<img width="1106" alt="brightness" src="https://github.com/Chenxy875/UIRE-Net/assets/121841006/e2824d09-2963-4c88-9421-116d29df93a5">

<img width="1031" alt="COMPARE" src="https://github.com/Chenxy875/UIRE-Net/assets/121841006/dbb89115-f872-483b-8545-105362dd611d">
